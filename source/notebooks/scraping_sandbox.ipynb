{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/code\n"
     ]
    }
   ],
   "source": [
    "%cd /code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.service.datasets import DATA\n",
    "from source.library.scraping import scrape_all_urls#, scrape_urls\n",
    "\n",
    "# This is needed because openai.text_completion calls asynchronous functions but\n",
    "# Jupyter is already running its own event loop.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10916\n",
      "('https://python.langchain.com/en/latest', 'Welcome to LangChain # LangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model via an API, but will also: Be data-aware : connect a language model to other sources of data Be agentic : allow a language model to interact with its environment The LangChain framework')\n"
     ]
    }
   ],
   "source": [
    "langchain_doc_chunks = DATA.langchain_doc_chunks.load()\n",
    "print(len(langchain_doc_chunks))\n",
    "print(langchain_doc_chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "persist_directory = '/code/.vectordb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: /code/.vectordb/\n",
      "No embedding_function provided, using default embedding function: SentenceTransformerEmbeddingFunction\n",
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "vectordb = Chroma(persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Source code for langchain.document_loaders.hn \"\"\"Loader that loads HN.\"\"\" from typing import Any , List from langchain.docstore.document import Document from langchain.document_loaders.web_base import WebBaseLoader [docs] class HNLoader ( WebBaseLoader ): \"\"\"Load Hacker News data from either main page results or the comments page.\"\"\" [docs] def load ( self ) -> List [ Document ]: \"\"\"Get important', metadata={'url': 'https://python.langchain.com/en/latest/_modules/langchain/document_loaders/hn.html'}),\n",
       " Document(page_content=': Any ) [source] # Loader that uses unstructured to load word documents. class langchain.document_loaders. WebBaseLoader ( web_path : Union [ str , List [ str ] ] , header_template : Optional [ dict ] = None ) [source] # Loader that uses urllib and beautiful soup to load webpages. aload ( ) â†’ List [ langchain.schema.Document ] [source] # Load text from the urls in web_path async into Documents.', metadata={'url': 'https://python.langchain.com/en/latest/reference/modules/document_loaders.html'}),\n",
       " Document(page_content='DirectoryLoader from langchain.document_loaders.pdf import PyPDFLoader from langchain.document_loaders.web_base import WebBaseLoader [docs] class BlackboardLoader ( WebBaseLoader ): \"\"\"Loader that loads all documents from a Blackboard course. This loader is not compatible with all Blackboard courses. It is only compatible with courses that use the new Blackboard interface. To use this loader, you', metadata={'url': 'https://python.langchain.com/en/latest/_modules/langchain/document_loaders/blackboard.html'}),\n",
       " Document(page_content='Source code for langchain.document_loaders.imsdb \"\"\"Loader that loads IMSDb.\"\"\" from typing import List from langchain.docstore.document import Document from langchain.document_loaders.web_base import WebBaseLoader [docs] class IMSDbLoader ( WebBaseLoader ): \"\"\"Loader that loads IMSDb webpages.\"\"\" [docs] def load ( self ) -> List [ Document ]: \"\"\"Load webpage.\"\"\" soup = self . scrape () text =', metadata={'url': 'https://python.langchain.com/en/latest/_modules/langchain/document_loaders/imsdb.html'}),\n",
       " Document(page_content='( f \"Loaded { len ( documents ) } pages of PDFs from { loader . web_path } \" )', metadata={'url': 'https://python.langchain.com/en/latest/_modules/langchain/document_loaders/blackboard.html'})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vectordb.similarity_search(query=\"How to use document loader for webpage?\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import VectorDBQA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "collection = client.create_collection('sample_collection')\n",
    "\n",
    "documents = []\n",
    "metadatas = []\n",
    "\n",
    "for url, chunk in langchain_doc_chunks:\n",
    "        documents.append(chunk)\n",
    "        metadatas.append({'url': url})\n",
    "\n",
    "collection.add(\n",
    "    documents=documents, # we embed for you, or bring your own\n",
    "    metadatas=metadatas, # filter on arbitrary metadata!\n",
    "    ids=[str(x) for x in range(len(documents))], # must be unique for each doc \n",
    ")\n",
    "\n",
    "print(np.mean([len(x) for x in documents]))\n",
    "print(np.max([len(x) for x in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(documents[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "    query_texts=\"What is a document loader?\",\n",
    "    n_results=5,\n",
    "    # where={\"metadata_field\": \"is_equal_to_this\"}, # optional filter\n",
    "    # where_document={\"$contains\":\"search_string\"}  # optional filter\n",
    ")\n",
    "print(len(results['documents'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
